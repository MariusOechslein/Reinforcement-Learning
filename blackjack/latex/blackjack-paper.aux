\relax 
\citation{b1}
\citation{b1}
\citation{b1}
\citation{b4}
\citation{b4}
\citation{b1}
\citation{b2}
\citation{b1}
\citation{b4}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {I-A}}Blackjack and Reinforcement Learning}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {I-B}}Reinforcement Learning for Blackjack}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {I-C}}Deep Reinforcement Learning}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Methods}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}The Blackjack Environment}{1}{}\protected@file@percent }
\citation{b1}
\citation{b1}
\citation{b4}
\citation{b4}
\citation{b4}
\citation{b4}
\citation{b4}
\citation{b4}
\citation{b5}
\citation{b4}
\citation{b4}
\citation{b2}
\citation{b2}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}State-action space}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Reinforcement Learning methods}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {II-C}1}Monte Carlo Control}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {II-C}2}SARSA}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {II-C}3}Q-Learning}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Deep Q-Learning}{2}{}\protected@file@percent }
\citation{b2}
\citation{b6}
\citation{b2}
\citation{b2}
\citation{b4}
\citation{b2}
\citation{b6}
\citation{b6}
\citation{b6}
\citation{b6}
\citation{b1}
\citation{b1}
\citation{b4}
\citation{b4}
\citation{b1}
\newlabel{replay-buffer}{{\mbox  {II-D}1}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {II-D}1}Experience Replay Buffer}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {II-D}2}Target Neural Network}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Experiments and Evaluation}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Monte Carlo Control policy after 100 million episodes. From own calculations.}}{3}{}\protected@file@percent }
\newlabel{fig:monte-carlo-basic-strategy}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces SARSA state-value function after 100 million episodes for case: no-usable ace. From own calculations.}}{3}{}\protected@file@percent }
\newlabel{fig:sarsa-state-value-basic}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Basic Strategy}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Complete Point Count Sytem}{3}{}\protected@file@percent }
\citation{b1}
\citation{b1}
\citation{b1}
\citation{b4}
\citation{b1}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces DQN policy after 180 thousand episodes with a card counting score of 7. From own calculations.}}{4}{}\protected@file@percent }
\newlabel{fig:dqn-card-counting-7}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Q-Learning with advanced counting method. All cards have been played. From own calculations.}}{4}{}\protected@file@percent }
\newlabel{fig:q-learning-advanced-all-cards-played}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Increased state space - counting all cards}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}1}Monte Carlo Control, SARSA and Q-Learning}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Q-Learning with advanced counting method. Only 5 and 8 have not been played. From own calculations.}}{4}{}\protected@file@percent }
\newlabel{fig:q-learning-advanced-5-8-not-played}{{5}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Q-Learning with advanced counting method. Every other card has been played, starting from Ace. From own calculations.}}{4}{}\protected@file@percent }
\newlabel{fig:q-learning-advanced-every-other}{{6}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}2}Deep Q-Learning}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Deep Q-Learning with advanced counting method. Rewards over the first 10.000 episodes. From own calculations.}}{4}{}\protected@file@percent }
\newlabel{fig:dqn-rewards-over-time}{{7}{4}}
\citation{b1}
\citation{b2}
\citation{b2}
\citation{b2}
\bibcite{b1}{1}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Deep Q-Learning with advanced counting method. Every other card has been played, starting from Ace. From own calculations.}}{5}{}\protected@file@percent }
\newlabel{fig:dqn-advanced-every-other}{{8}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Deep Q-Learning with advanced counting method. Only low cards (2,3,4,5,6) have been played. From own calculations.}}{5}{}\protected@file@percent }
\newlabel{fig:dqn-advanced-only-low}{{9}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{5}{}\protected@file@percent }
\gdef \@abspage@last{5}
